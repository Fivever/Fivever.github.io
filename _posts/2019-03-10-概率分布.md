---
layout: post
title: 概率分布
date: 2019-03-10
categories: 模式识别与机器学习
tag: 读书笔记
published: true
---

* content
{:toc}

# 概率分布

## 二元变量

伯努利分布（英语：Bernoulli distribution，又名两点分布或者0-1分布，是一个离散型概率分布，为纪念瑞士科学家雅各布·伯努利而命名。）若伯努利试验成功，则伯努利随机变量取值为1。若伯努利试验失败，则伯努利随机变量取值为0。记其成功概率为 <img src="https://latex.codecogs.com/png.latex?\inline&space;  {\displaystyle p(0{\leq }p{\leq }1)} ">，失败概率为<img src="https://latex.codecogs.com/png.latex?\inline&space;  {\displaystyle q=1-p} ">。则

- 其概率质量函数为：
<img src="https://latex.codecogs.com/png.latex?\inline&space;  {\displaystyle f_{X}(x)=p^{x}(1-p)^{1-x}.} ">
- 其期望值为：
<img src="https://latex.codecogs.com/png.latex?\inline&space;  {\displaystyle \operatorname {E} [X]=\sum _{i=0}^{1}x_{i}f_{X}(x)=0+p=p}  ">
- 其方差为：
<img src="https://latex.codecogs.com/png.latex?\inline&space;  {\displaystyle \operatorname {var} [X]=\sum _{i=0}^{1}(x_{i}-E[X])^{2}f_{X}(x)=(0-p)^{2}(1-p)+(1-p)^{2}p=p(1-p)=pq} ">

在介绍接下来的内容之前，我们先了解一下似然函数的意义。

	概率，用于在已知一些参数的情况下，预测接下来在预测上所得到的结果；
    似然性，则是用于在已知某些预测所得到的结果时，对有关事物之性质的参数进行估计

在这种意义上，似然函数可以理解为条件概率的逆反。在已知某个参数B时，事件A会发生的概率写作：

<img src="https://latex.codecogs.com/png.latex?\inline&space;  P(A\,|\,B)={\frac{P(A,B)}{P(B)}} ">

利用贝叶斯定理，

<img src="https://latex.codecogs.com/png.latex?\inline&space;  P(B\,|\,A)={\frac  {P(A\,|\,B)\;P(B)}{P(A)}}">

因此，我们可以反过来构造表示似然性的方法：已知有事件A发生，运用似然函数 <img src="https://latex.codecogs.com/png.latex?\inline&space;  {\mathbb  {L}}(B\,|\,A)">，我们估计参数B的可能性。形式上，似然函数也是一种条件概率函数，但我们关注的变量改变了：

<img src="https://latex.codecogs.com/png.latex?\inline&space;  b\mapsto P(A\,|\,B=b)\!">

注意到这里并不要求似然函数满足归一性：<img src="https://latex.codecogs.com/png.latex?\inline&space;  \sum _{{b\in {\mathcal  {B}}}}P(A\,|\,B=b)=1">。一个似然函数乘以一个正的常数之后仍然是似然函数。对所有<img src="https://latex.codecogs.com/png.latex?\inline&space;  {\displaystyle \alpha >0} ">，都可以有似然函数：

<img src="https://latex.codecogs.com/png.latex?\inline&space;  L(b\,|\,A)=\alpha \;P(A\,|\,B=b)\!">

现在假设我们有一个数据集<img src="https://latex.codecogs.com/png.latex?\inline&space;  D={x_1,\ x_2,\ ...,\ x_N}">独立同分布，那么该数据集的似然函数是：<img src="https://latex.codecogs.com/png.latex?\inline&space;  p(D\,|\,\mu)=\prod_{n=1}^Np(x_n,\mu)=\prod_{n=1}^N\mu^{x_n}(1-\mu)^{1-x_n} ">

此时，该似然函数的意义是，以<img src="https://latex.codecogs.com/png.latex?\inline&space;  \mu">为自变量，实验时收集到数据集D的可能性的大小（在归一化条件下，就是收集到数据集D的概率），也就是说，对于不同的<img src="https://latex.codecogs.com/png.latex?\inline&space;  \mu">，收集到数据集D的概率是不同的，那么最大似然估计就是在该似然函数取得最大值时<img src="https://latex.codecogs.com/png.latex?\inline&space;  \mu">的取值。

为了方便求导，这里取对数似然函数的对<img src="https://latex.codecogs.com/png.latex?\inline&space;  \mu">的导数

<img src="https://latex.codecogs.com/png.latex?\inline&space;  \frac{d\,ln\,p(D\,|\,\mu)}{d\,\mu}=0 ">

解得：

<img src="https://latex.codecogs.com/png.latex?\inline&space;  \mu_{ML}=\frac1N\sum_{n=1}^Nx_n ">

### B分布

Β分布也称贝塔分布（Beta distribution），是指一组定义在<img src="https://latex.codecogs.com/png.latex?\inline&space;  {\displaystyle (0,1)} ">区间的连续概率分布，有两个参数 <img src="https://latex.codecogs.com/png.latex?\inline&space;  {\displaystyle \alpha ,\beta >0} ">。

Β分布的概率密度函数是：

<img src="https://latex.codecogs.com/png.latex?\inline&space;  f(x;\alpha,\beta) = \frac{x^{\alpha-1}(1-x)^{\beta-1}}{\int_0^1 u^{\alpha-1} (1-u)^{\beta-1}\, du} = \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}\, x^{\alpha-1}(1-x)^{\beta-1}">

Beta函数：

<img src="https://latex.codecogs.com/png.latex?\inline&space; \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)}={\int_0^1 u^{\alpha-1} (1-u)^{\beta-1}\, du}">

归一化：

<img src="https://latex.codecogs.com/png.latex?\inline&space; {\int_0^1 u^{\alpha-1} (1-u)^{\beta-1}\, du}=1">

其均值和方差分别为

<img src="https://latex.codecogs.com/png.latex?\inline&space;  \mu =\operatorname {E}(X)={\frac  {\alpha }{\alpha +\beta }} ">

<img src="https://latex.codecogs.com/png.latex?\inline&space;  {\displaystyle \operatorname {Var} (X)=\operatorname {E} (X-\mu )^{2}={\frac {\alpha \beta }{(\alpha +\beta )^{2}(\alpha +\beta +1)}}} ">

在上式中，我们还需介绍一个函数，伽马函数。

在数学中，<img src="https://latex.codecogs.com/png.latex?\inline&space;  {\displaystyle \Gamma \,} ">函数，也叫做伽玛函数（Gamma函数），是阶乘函数在实数与复数域上的扩展。如果n为正整数，则：

<img src="https://latex.codecogs.com/png.latex?\inline&space;  {\displaystyle \Gamma (n)=(n-1)!} ">

对于实数部分为正的复数<img src="https://latex.codecogs.com/png.latex?\inline&space; z">，伽玛函数定义为：

<img src="https://latex.codecogs.com/png.latex?\inline&space;  {\displaystyle \Gamma (z)=\int _{0}^{\infty }{\frac {t^{z-1}}{\mathrm {e} ^{t}}}\,{\rm {d}}t} ">

值得注意的是，因为在贝叶斯统计中，如果后验分布与先验分布属于同类，则先验分布与后验分布被称为共轭分布，而先验分布被称为似然函数的共轭先验。我们发现上述先验函数和B分布的概率密度函数的函数形式相似，所以B分布的概率密度函数与该先验函数具有共轭性。

#### 贝叶斯概率

先验概率分布：  <img src="https://latex.codecogs.com/png.latex?\inline&space; p(w)">

观测数据：     <img src="https://latex.codecogs.com/png.latex?\inline&space; D=\{t_1,t_2,...,t_N\}">

似然函数：     <img src="https://latex.codecogs.com/png.latex?\inline&space; p(D|w)">

朴素贝叶斯模型：<img src="https://latex.codecogs.com/png.latex?\inline&space; P(A|B)=\frac{p(A|B)p(A)}{p(B)}">

后验概率:      <img src="https://latex.codecogs.com/png.latex?\inline&space; P(w|D)=\frac{p(D|w)p(w)}{p(D)}">

后验概率与似然函数和先验概率的乘积成正比

由上知，后验概率与先验和似然的乘积成正比，所以令后验概率=似然函数*先验概率

p